---
layout: post
title: 'EM Algorithm 쉽게 이해하기'
subtitle: 'EM Algorithm 쉽게 이해하기'
categories: datascience
tags: statistics
comments: true
---

EM 알고리즘은 통계 모델의 수식을 정확히 풀 수 없을때 최대 가능도를 구하는데 사용된다. 

이런 통계 모델은 보통 잠재변수(latent variables)와 관측할 수 없는 매개변수(unknown parameters), 관측된데이터(known data)로 구성되어있다.

예를들면 혼합모델에서 매 관측값이 그에 상응하는 잠재변수를 가지고 있다고 가정할 수 있다. (→ 딱 GMM) 

* 평균μ,분산Σ, 가중치π, 부담율γ

# 1. 부담율

관찰되지 않은 잠재변수의 추정치가 어떤 클러스터에 포함될것인지 알려주는 조건부 확률

π의 사후분포 

데이터 x가 클러스터 k에서 생성되었을 확률

확률적 추정값으로 0에서 1사이의 실수값 

# 2. EM 알고리즘

간단히 말해, MLE(최대가능도추정법)을 사용해서 관측된 데이터에 알맞은 모델의 변수를 추정한다. 어떤 모델의 변수를 모르는 경우에 이를 추정하는 방법. 초기에 랜덤하게 모델 변수를 설정한 상태에서 관측 데이터가 이 모델로부터 생성되었을 확률을 계산. 

1. 클러스터 파라미터(μ, π, Σ) 랜덤 초기화
2. E Step (Expectation Step)
    - 샘플을 클러스터에 할당
    - μ, π, Σ 로 부담율γ 산출
    - 각 가우스 함수 값을 계산 후 합이 1이 되도록 정규화
    - k-means로 따지자면 평균(센트로이드)구하는과정임
3. M Step (Maximization Step)
    - 현 시점의 γ를 이용하여 μ, π, Σ 를 산출
    - 클러스터 업데이트
    - k-means로 따지자면 새 센트로이드로 중심 옮기는 과정임
4. 각 단계가 임계치보다 작을 때까지 반복

→ 약간 K-means와 비슷한 부분이 있다..


> [https://m.blog.naver.com/lhm0812/220709231513](https://m.blog.naver.com/lhm0812/220709231513)